(python_copy) D:\Projects\mnist>python mnist.py
----------KNN---------
Test accuracy of KNN :0.9688
confusion matrix of KNN:
[[ 974    1    1    0    0    1    2    1    0    0]
 [   0 1133    2    0    0    0    0    0    0    0]
 [  11    8  991    2    1    0    1   15    3    0]
 [   0    3    3  976    1   13    1    6    3    4]
 [   3    7    0    0  944    0    4    2    1   21]
 [   5    0    0   12    2  862    4    1    2    4]
 [   5    3    0    0    3    2  945    0    0    0]
 [   0   22    4    0    3    0    0  988    0   11]
 [   8    3    5   13    6   12    5    5  913    4]
 [   5    7    3    9    7    3    1   10    2  962]]
classification report:
              precision    recall  f1-score   support

           0       0.96      0.99      0.98       980
           1       0.95      1.00      0.98      1135
           2       0.98      0.96      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.99      0.98       958
           7       0.96      0.96      0.96      1028
           8       0.99      0.94      0.96       974
           9       0.96      0.95      0.95      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

----------lg---------
Test accuracy of lg :0.9255
confusion matrix of lg:
[[ 963    0    0    3    1    3    4    4    2    0]
 [   0 1112    4    2    0    1    3    2   11    0]
 [   3   10  926   15    6    4   15    8   42    3]
 [   4    1   21  916    1   26    3    9   22    7]
 [   1    1    7    3  910    0    9    7   10   34]
 [  11    2    1   33   11  776   11    6   35    6]
 [   9    3    7    3    7   16  910    2    1    0]
 [   1    6   24    5    7    1    0  951    3   30]
 [   8    7    6   23    6   26   10   10  869    9]
 [   9    7    0   11   25    6    0   22    7  922]]
classification report:
              precision    recall  f1-score   support

           0       0.95      0.98      0.97       980
           1       0.97      0.98      0.97      1135
           2       0.93      0.90      0.91      1032
           3       0.90      0.91      0.91      1010
           4       0.93      0.93      0.93       982
           5       0.90      0.87      0.89       892
           6       0.94      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.87      0.89      0.88       974
           9       0.91      0.91      0.91      1009

    accuracy                           0.93     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.93      0.93      0.93     10000

----------nb---------
Test accuracy of nb :0.5558
confusion matrix of nb:
[[ 870    0    3    5    2    5   31    1   35   28]
 [   0 1079    2    1    0    0   10    0   38    5]
 [  79   25  266   91    5    2  269    4  271   20]
 [  32   39    6  353    2    3   51    8  409  107]
 [  19    2    5    4  168    7   63    7  210  497]
 [  71   25    1   20    3   44   40    2  586  100]
 [  12   12    3    1    1    7  895    0   26    1]
 [   0   15    2   10    5    1    5  280   39  671]
 [  13   72    3    7    3   11   12    4  648  201]
 [   5    7    3    6    1    0    1   13   18  955]]
classification report:
              precision    recall  f1-score   support

           0       0.79      0.89      0.84       980
           1       0.85      0.95      0.90      1135
           2       0.90      0.26      0.40      1032
           3       0.71      0.35      0.47      1010
           4       0.88      0.17      0.29       982
           5       0.55      0.05      0.09       892
           6       0.65      0.93      0.77       958
           7       0.88      0.27      0.42      1028
           8       0.28      0.67      0.40       974
           9       0.37      0.95      0.53      1009

    accuracy                           0.56     10000
   macro avg       0.69      0.55      0.51     10000
weighted avg       0.69      0.56      0.52     10000

----------dt---------
Test accuracy of dt :0.8872
confusion matrix of dt:
[[ 912    2    7    3    2   19   14    7    7    7]
 [   0 1105    6    3    1    5    4    3    6    2]
 [   8    4  911   21   12    7   16   22   26    5]
 [   8    9   29  845    3   49    6   17   23   21]
 [   6    5   21    7  861    4   17   11   12   38]
 [  14    5    9   34    6  759   22    0   25   18]
 [  14    4   12    6   22   19  865    4   10    2]
 [   2    9   34   17    9    8    3  926    5   15]
 [   9    8   22   36   20   21   14    8  815   21]
 [  11    7    9   18   29   18    4   18   22  873]]
classification report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.95      0.97      0.96      1135
           2       0.86      0.88      0.87      1032
           3       0.85      0.84      0.84      1010
           4       0.89      0.88      0.88       982
           5       0.83      0.85      0.84       892
           6       0.90      0.90      0.90       958
           7       0.91      0.90      0.91      1028
           8       0.86      0.84      0.85       974
           9       0.87      0.87      0.87      1009

    accuracy                           0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000

----------rf---------
Test accuracy of rf :0.9232
confusion matrix of rf:
[[ 960    0    2    1    1    5    4    1    5    1]
 [   1 1121    4    3    0    2    0    1    3    0]
 [  14   10  944    6    7    4    9   18   18    2]
 [   6    3   25  920    2   28    2    6   13    5]
 [   5    2    7    6  921    3    6    1    5   26]
 [  11    2    1   42    7  795   12    5   10    7]
 [  23    3    3    2   14   11  899    0    2    1]
 [   4    8   30    6    7    3    1  947    5   17]
 [  11    3   26   31   21   21    7    5  836   13]
 [  10    9   10   12   35   10    3   16   15  889]]
classification report:
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.97      0.99      0.98      1135
           2       0.90      0.91      0.91      1032
           3       0.89      0.91      0.90      1010
           4       0.91      0.94      0.92       982
           5       0.90      0.89      0.90       892
           6       0.95      0.94      0.95       958
           7       0.95      0.92      0.93      1028
           8       0.92      0.86      0.89       974
           9       0.93      0.88      0.90      1009

    accuracy                           0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000

----------ada---------
Test accuracy of ada :0.8716
confusion matrix of ada:
[[ 920    0    9    3    1   19   17    3    5    3]
 [   1 1067   24    4    0    1    3   11   24    0]
 [   3   14  893   36    6    9   18   10   39    4]
 [   4    1   26  883    1   42    3   11   33    6]
 [   2    1   13    7  852    0   14   16   10   67]
 [  14    1    6   57    6  713   21    7   54   13]
 [  11    4   30    5   16   29  858    2    3    0]
 [   2    5   28   17    5    2    0  913    3   53]
 [   8   12   35   42    8   36   12    9  800   12]
 [   7    8    3   10   59    5    0   90   10  817]]
classification report:
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.96      0.94      0.95      1135
           2       0.84      0.87      0.85      1032
           3       0.83      0.87      0.85      1010
           4       0.89      0.87      0.88       982
           5       0.83      0.80      0.82       892
           6       0.91      0.90      0.90       958
           7       0.85      0.89      0.87      1028
           8       0.82      0.82      0.82       974
           9       0.84      0.81      0.82      1009

    accuracy                           0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000

----------gb---------
Test accuracy of gb :0.8001
confusion matrix of gb:
[[ 913    1    4    2    8    6    5    2   36    3]
 [   0 1067   14   17    1    0    8    0   28    0]
 [  63   50  766   27   27    1   13    9   65   11]
 [  19   12   44  815   12   12    3   12   42   39]
 [  15   19    7   12  791   20    5   11   42   60]
 [  31   15    8  126   53  536   25   10   40   48]
 [  21   10   13    5   60   25  790    0   32    2]
 [  12   32   10   19   38    4    0  788   10  115]
 [   7   56   17   52   18   30    5    5  740   44]
 [  14   16    7   21   59    7    0   71   19  795]]
classification report:
              precision    recall  f1-score   support

           0       0.83      0.93      0.88       980
           1       0.83      0.94      0.88      1135
           2       0.86      0.74      0.80      1032
           3       0.74      0.81      0.77      1010
           4       0.74      0.81      0.77       982
           5       0.84      0.60      0.70       892
           6       0.93      0.82      0.87       958
           7       0.87      0.77      0.81      1028
           8       0.70      0.76      0.73       974
           9       0.71      0.79      0.75      1009

    accuracy                           0.80     10000
   macro avg       0.81      0.80      0.80     10000
weighted avg       0.81      0.80      0.80     10000

----------xgb---------
Test accuracy of xgb :0.9791
confusion matrix of xgb:
[[ 969    0    0    0    0    2    4    1    3    1]
 [   0 1125    1    3    0    1    2    1    2    0]
 [   5    0 1007    8    2    0    0    5    5    0]
 [   0    0    5  990    0    4    0    6    4    1]
 [   0    0    4    1  957    0    4    0    2   14]
 [   2    0    0    8    0  869    3    4    3    3]
 [   5    3    1    0    1    5  941    0    2    0]
 [   1    2   11    4    1    0    0 1000    1    8]
 [   3    1    2    1    4    1    2    2  954    4]
 [   6    4    2    5    5    1    0    4    3  979]]
classification report:
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.98      1032
           3       0.97      0.98      0.98      1010
           4       0.99      0.97      0.98       982
           5       0.98      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.97      0.98      0.98       974
           9       0.97      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

----------svm---------
Test accuracy of svm :0.9792
confusion matrix of svm:
[[ 973    0    1    0    0    2    1    1    2    0]
 [   0 1126    3    1    0    1    1    1    2    0]
 [   6    1 1006    2    1    0    2    7    6    1]
 [   0    0    2  995    0    2    0    5    5    1]
 [   0    0    5    0  961    0    3    0    2   11]
 [   2    0    0    9    0  871    4    1    4    1]
 [   6    2    0    0    2    3  944    0    1    0]
 [   0    6   11    1    1    0    0  996    2   11]
 [   3    0    2    6    3    2    2    3  950    3]
 [   3    4    1    7   10    2    1    7    4  970]]
classification report:
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.97      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.99      0.99       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.97      0.96      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

----------svm with grid search---------
----------SVM GRID SEARCH---------
Best Parameters we got : {'C': 1, 'class_weight': 'balanced', 'kernel': 'rbf'}
Test accuracy of tuned SVM: 0.9796
confusion matrix of tuned SVM:
[[ 973    0    1    0    0    2    1    1    2    0]
 [   0 1126    3    1    0    1    1    1    2    0]
 [   6    0 1006    2    1    0    2    7    7    1]
 [   0    0    2  995    0    2    0    5    5    1]
 [   0    0    5    0  961    0    3    0    2   11]
 [   2    0    0    7    0  873    4    1    4    1]
 [   6    2    0    0    2    3  944    0    1    0]
 [   0    6   11    1    2    0    0  995    2   11]
 [   3    0    2    6    3    2    2    2  951    3]
 [   3    3    1    7   10    2    1    6    4  972]]
classification report:
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.99      0.99       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.97      0.96      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


(python_copy) D:\Projects\mnist>